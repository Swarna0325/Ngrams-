# -*- coding: utf-8 -*-
"""ngrams(merged).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X7MKhBY6p9sHP1LiLTLJ3mjURgboUPDJ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
plt.style.use(style='seaborn')
# %matplotlib inline

df=pd.read_csv('./Merged_Abstracts.csv',encoding = "ISO-8859-1")
df.head()

df.info()
df.isna().sum()

!pip install -q wordcloud
import wordcloud
import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger') 
from nltk.corpus import stopwords

import re
import unicodedata
import nltk
from nltk.corpus import stopwords
# add appropriate words that will be ignored in the analysis
ADDITIONAL_STOPWORDS = ['article']
import matplotlib.pyplot as plt

def basic_clean(Abstract):
  """
  A simple function to clean up the data. All the words that
  are not designated as a stop word is then lemmatized after
  encoding and basic regex parsing are performed.
  """
  wnl = nltk.stem.WordNetLemmatizer()
  stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS
  Abstract = (unicodedata.normalize('NFKD', Abstract)
    .encode('ascii', 'ignore')
    .decode('utf-8', 'ignore')
    .lower())
  words = re.sub(r'[^\w\s]', '', Abstract).split()
  return [wnl.lemmatize(word) for word in words if word not in stopwords]

words = basic_clean(''.join(str(df['Abstract'].tolist())))
words

(pd.Series(nltk.ngrams(words, 2)).value_counts())[:50]

(pd.Series(nltk.ngrams(words, 3)).value_counts())[:50]

bigrams_series = (pd.Series(nltk.ngrams(words, 2)).value_counts())[:20]
trigrams_series = (pd.Series(nltk.ngrams(words, 3)).value_counts())[:20]

bigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))

bigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))
plt.title('20 Most Frequently Occuring Bigrams')
plt.ylabel('Bigram')
plt.xlabel('# of Occurances')